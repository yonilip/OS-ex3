

2.

we would use 7 threads for multiThreadLevel.
in our implementation shuffle thread does not count as one of the thread in
multiThreadLevel (creating multiThreadLevel amount of execMap and execReduce).
and ignoring  main thread since it will waits (for join) most time framework
runs,
this way 8 threads can run on each core in parallel manner: 7 will execute map
and reduce actions, anf one will shuffle.


3.
    a. Utilizing multi-cores:

        a- Nira:
        Nira's thread will run on one core at most and will not utilize multi-core actions.
        there is no concurrency.
        b- Moti:
        we cannot know for sure if Moti's program will support multi-threading.
        it is able to utilize seperate cores but won't necessarily do so.
        c- Danny:
        Danny uses user-level threads so one thread will run at any given time.
        Concurrency is not achieved.
        d- Galit:
        Galit has the best approach, each thread is actually a process, so the
        OS will try and take advantage of multi-core abilities: running each
        process on an available core.

     b. Creating sophisticated scheduler ability:

        a- Nira:
        each time main thread will get run time from the kernel, the thread
        will run.
        b- Moti:
        OS responsible of scheduling kernel level threads, it can be affected by using mutexes, condition
        variables, barriers...
        c- Danny:
        user level threads scheduling isnt difficult and can be implemented
        using scheduling
        algorithm (such as Round Robin that we implemented in ex2).
        d- Galit:
        OS would be in charge of scheduling each process and circumventing it
        would be very difficult.

     c. Communication between threads and processes:

        a- Nira:
        thread can easily communicate with itself
        b- Moti:
        threads share the same memory pool of their process. We can easily
        implement a communication between memory using locks and flags.
        c- Danny:
        we can access the same memory for each thread by locks and flags,
        communication is fast.
        d- Galit:
        communication between processes will take a long time since multiple
        processes communication is done by reading and writing into the
        pipe) which is slower then shared memory communication (Danny and Moti).

     d. Ability to progress while a thread is blocked:

         a- Nira:
         Nira has only one thread so in case it will be blocked, the whole
         process will be blocked.
         b- Moti:
         in case one thread is blocked, there will be other thread that c
         ontinue with the map reduce work ad the process will continue.
         c- Danny:
         User-level threads doesn't cannot progress while a certain thread
         is blocked.
         OS takes all user level threads as one unit, so the process will be
         blocked.
         d- Galit:
         blocking one thread will not block others. OS will manage each process
         and runs them on different cores when possible. If a thread is blocked
         then the OS will run another process in its place.


     e. Overall speed:

          a- Nira:
          In case context switch is expensive, Nira's solution will be
          better then Moti's and Galit's since a single thread is running-
          no context switching!
          in most cases framework contains many items so the major time would
          be spent in the map and reduce stages where more threads/processes
          would save time using concurrency
          b- Moti:
          Moti's solution will be the faster among othe solutions.
          creation and communication time are faster using threads over processes
          (threads communicate
          through shared memory in contrast to I/O actions). synchronization
          of our shared data forces us to use mutexes and flags which also take
          time but we think in overall this will probably be the best way to
          implement this task.
          c- Danny:
          Danny uses user level threads, not creating separate processes or
          kernel level threads.
          His solution may still be faster than Nira's depending on the cost
          vs benefit of the context switches.
          But may be slower than others
          for the same reason Nira's will most likely be slower. And may
          be faster than the other's due to the lower cost of creating
          user-level threads and doing context switches.
          d- Galit:
          Galit solution will be fast since Galit since it takes advantage of
          any possible multi-cores available on the machine the program runs on.
          it can be slower than multithreading due to the time it takes to create
          processes and the time it takes us to switch between them.

4.

Kernel-level thread:
	Global variables
	Heap

User-level thread:
	Global variables
	Heap

Process:
	None

6.

Process|Arrival Time| running Time| Priority (higher number - higher priority)
P1      0                10           1
P2      1                1            3
P3      3                2            2
P4      7                12           3
P5      8                1            1

RR (quantum = 2):
    -Turnaround time: (18+2+4+19+4)/5 = 9.4
    -Average wait time: 8+1+2+7+3)/5 = 4.2

FCFS:
    -Turnaround time: (10+10+10+18+18)/5 = 13.2
    -Average wait time: (0+9+8+6+17)/5 = 8
SRTF:
    -Turnaround time: (14+1+2+19+1)/5 = 7.4
    -Average wait time: (4+0+0+7+0)/5 = 2.2

Priority Scheduling:
    -Turnaround time : (25+1+2+12+18)/5 = 11.6
    -Average wait time : (15+0+0+0+17)/5 = 6.4